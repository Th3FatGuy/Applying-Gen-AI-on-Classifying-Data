{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e775bd91",
   "metadata": {},
   "source": [
    "# Applying Google AI on Classifying Data from Job Post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa6846",
   "metadata": {},
   "source": [
    "## Case scenerio:\n",
    "There are numerous course alternatives available to students within the same major before they enroll in a university, academy, or college. There is a lack of specialized knowledge and skills in real-life jobs, however, resulting from the majority of these courses' shallow instruction, which makes it challenging for students to obtain them. On the other hand, a lack of highly qualified workers for many organizations in emerging nations makes hiring difficult, particularly for senior roles that still need more talent. By using Google Gen AI to categorize data and skill sets, this initiative hopes to assist educational institutions in identifying and improving the specialized skills and tools required in their curricula so that students are better equipped for the workforce.\n",
    "\n",
    "📄 **Use case of project**:\n",
    "- Using Selenium with Beutiful Soup to collect data from career website\n",
    "- Classifying different categories from job post using Google Generative AI\n",
    "\n",
    "🤖 **Gen AI capabilities**:\n",
    "- Document understanding: Understanding different job post\n",
    "- Structured output/JSON mode: Return result as JSON\n",
    "- Few-shot prompting: Classifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install pandas selenium tldextract beutyfulsoup4 requests\n",
    "# %pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c772a2",
   "metadata": {},
   "source": [
    "Callout libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360a1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from google import genai\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    ")\n",
    "\n",
    "import tldextract\n",
    "import httpx\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import json\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.utils import get_column_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce3a79",
   "metadata": {},
   "source": [
    "Read config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "572c368f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfigFile.properties']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigParser()\n",
    "config.read('ConfigFile.properties')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6062542",
   "metadata": {},
   "source": [
    "Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c31ff439",
   "metadata": {},
   "outputs": [],
   "source": [
    "today =  datetime.today().strftime('%Y-%m-%d')\n",
    "company_url = config.get('URL', 'url.broadcom')\n",
    "googleai_key = config.get('API', 'api.key_googleai')\n",
    "company = \"Broadcom\"\n",
    "webdriver_service = Service(config.get('URL', 'url.chromedriver')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a29529",
   "metadata": {},
   "source": [
    "Define functions:\n",
    "- **collect_job_links()**: function to collect career links from Broadcom career website\n",
    "- **convert_posted_date()**: the date on career website are being set as: *\"Posted Today\", \"Posted Yesterday\", \"Posted 2 days ago\", etc.*, so the function will converted to date as type ***%d-%m-&Y***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8424fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_job_links(driver):\n",
    "    job_urls = []\n",
    "    while True:\n",
    "        try:\n",
    "            job_links = driver.find_elements(By.XPATH, \"//a[@data-automation-id='jobTitle']\")\n",
    "            job_urls.extend([link.get_attribute(\"href\") for link in job_links])\n",
    "            \n",
    "            next_button = driver.find_element(By.XPATH, \"//button[@data-uxi-element-id='next']\")\n",
    "            \n",
    "            if not next_button.is_enabled():\n",
    "                break\n",
    "            \n",
    "            next_button.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            print(\"No more pages or next button not found, stopping...\")\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout while loading page, stopping...\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            break\n",
    "    \n",
    "    return job_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3624a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_posted_date(posted_str):\n",
    "    today = datetime.today()\n",
    "    \n",
    "    if 'Today' in posted_str:\n",
    "        return today.strftime(\"%d-%m-%Y\")\n",
    "    elif 'Yesterday' in posted_str:\n",
    "        return (today - timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    match = re.search(r'(\\d+)', posted_str)\n",
    "    if match:\n",
    "        days_ago = int(match.group(1))\n",
    "        return (today - timedelta(days=days_ago)).strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d1a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m driver = webdriver.Chrome(service=webdriver_service)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[32m      3\u001b[39m company = tldextract.extract(company_url).domain\n\u001b[32m      4\u001b[39m driver.get(company_url)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "time.sleep(5)  \n",
    "company = tldextract.extract(company_url).domain\n",
    "driver.get(company_url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "try:\n",
    "    cookie_banner = driver.find_element(By.ID, \"onetrust-policy\")\n",
    "    dismiss_button = cookie_banner.find_element(By.XPATH, \"//button[contains(text(), 'Accept') or contains(text(), 'I Understand')]\") # Change the text if needed\n",
    "    dismiss_button.click()  # Accept cookies to remove the banner\n",
    "except NoSuchElementException:\n",
    "    print(\"No cookie banner found, proceeding...\")\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    job_links = collect_job_links(driver)\n",
    "except NoSuchElementException:\n",
    "    print(\"No job links found, proceeding...\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382beb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links_df = pd.DataFrame(job_links, columns=[\"Job Links\"])\n",
    "# For backup purposes, save the job links to a CSV file\n",
    "job_links_df.to_csv(\"Broadcom_job_links.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case that the ipynb restarts from the beginning, uncomment the following line to read the job links from the CSV file\n",
    "# job_links_df = pd.read_csv(\"Broadcom_job_links.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8946f48b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     65\u001b[39m             \u001b[38;5;66;03m# To avoid overwhelming the server, wait a bit before the next request\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m             \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m driver3.quit()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_job_data = []\n",
    "# For test case extract first 10 job links\n",
    "job_links_test = job_links_df['Job Links'][:10]\n",
    "driver3 = webdriver.Chrome(service=webdriver_service)\n",
    "with httpx.Client(timeout=10) as client:\n",
    "    for link in job_links_df['Job Links']:\n",
    "        driver3.get(link)\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver3.page_source, 'html.parser')\n",
    "            time.sleep(2)\n",
    "            job_metadata = {}\n",
    "            \n",
    "            job_title_tag = soup.find(\"h2\", {\"data-automation-id\": \"jobPostingHeader\"})\n",
    "            job_title = job_title_tag.get_text(strip=True) if job_title_tag else \"N/A\"\n",
    "\n",
    "            job_location_div = soup.find(\"div\", {\"data-automation-id\": \"locations\"})\n",
    "            job_locations = []\n",
    "            if job_location_div:\n",
    "                locations = job_location_div.find_all(\"dd\", class_=\"css-129m7dg\")\n",
    "                job_locations = [loc.get_text(strip=True) for loc in locations]\n",
    "            job_location = \"\\n \".join(job_locations) if job_locations else \"N/A\"\n",
    "\n",
    "            date_posted_div = soup.find(\"div\", {\"data-automation-id\": \"postedOn\"})\n",
    "            date_posted = \"N/A\"\n",
    "            if date_posted_div:\n",
    "                date_tag = date_posted_div.find(\"dd\", class_=\"css-129m7dg\")\n",
    "                date_posted = date_tag.get_text(strip=True) if date_tag else \"N/A\"\n",
    "            date_posted = convert_posted_date(date_posted)\n",
    "\n",
    "            job_id_div = soup.find(\"div\", {\"data-automation-id\": \"requisitionId\"})\n",
    "            job_id = \"N/A\"\n",
    "            if job_id_div:\n",
    "                job_id_tag = job_id_div.find(\"dd\", class_=\"css-129m7dg\")\n",
    "                job_id = job_id_tag.get_text(strip=True) if job_id_tag else \"N/A\"\n",
    "\n",
    "        \n",
    "            job_type_div = soup.find(\"div\", {\"data-automation-id\": \"time\"})\n",
    "            job_type = job_type_div.get_text(strip=True) if job_type_div else \"N/A\"\n",
    "            if job_type != \"N/A\":\n",
    "                job_type = job_type[9::]\n",
    "\n",
    "            job_description_elem = WebDriverWait(driver3, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//div[@data-automation-id='jobPostingDescription']\"))\n",
    "            )\n",
    "            job_text = job_description_elem.find_elements(By.CSS_SELECTOR, \"p, ul, ul li\")\n",
    "            job_description = \"\\n\".join([p.text for p in job_text])\n",
    "\n",
    "            job_data = {\n",
    "                \"Company\": company,\n",
    "                \"Job Title\": job_title,\n",
    "                \"Job Location\": job_location,\n",
    "                \"Date Posted\": date_posted,\n",
    "                \"Employment Type\": job_type,\n",
    "                \"Job ID\": job_id,\n",
    "                \"Job Context\": job_description,\n",
    "                \"Link\": link\n",
    "            }\n",
    "\n",
    "            all_job_data.append(job_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {link}: {e}\")\n",
    "        finally:\n",
    "            # To avoid overwhelming the server, wait a bit before the next request\n",
    "            time.sleep(15)\n",
    "\n",
    "driver3.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dict list into a DataFrame\n",
    "df = pd.DataFrame(all_job_data)\n",
    "\n",
    "# Save data to CSV file for backup\n",
    "df.to_excel(\"Broadcom_job_data.xlsx\", index=False)\n",
    "\n",
    "# Preview the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The promt is in Vietnamese, howeverm the response is in English.\n",
    "# If you want to change the prompt to English, please change the DEFINE_PROMPT variable below.\n",
    "DEFINE_PROMPT = \"\"\"\n",
    "Từ đoạn text sau, bạn hãy phân tích giúp tôi và trả lời các câu hỏi sau, kết quả trả về cho các variable tương ứng như sau:\n",
    "- work_category: Danh mục công việc này là gì? (VD: Software Engineer, Data Analyst, ...)\n",
    "- domain: phân loại mảng làm việc chính (ví dụ: IC Design, Software, Backend, Frontend, Embedded, DevOps, Firmware, System, v.v.) \n",
    "- job_description: Mô tả công việc này là cần làm những việc gì?\n",
    "- job_responsibility: Công việc này cần những trách nhiệm gì?\n",
    "- job_requirements: Công việc này cần những yêu cầu gì?\n",
    "- require_tools: Công việc này cần những kỹ năng về công cụ nào?\n",
    "- require_certificate: Công việc này cần những bằng cấp gì? (Không tính bằng đại học như master, bachelor, ...)\n",
    "- require_skills: Công việc này cần những kỹ năng gì?\n",
    "- job_experience: Công việc này cần những kinh nghiệm gì?\n",
    "- education_level: Bằng cấp học vấn cần thiết cho công việc này là gì? (VD: Bachelor's, Master's, PhD, ...)\n",
    "- education_major: Chuyên ngành học cần thiết cho công việc này là gì? (VD: Computer Science, Logistic, Engineering..., nếu không được nêu trong mô tả thì dự đoán những chuyên ngành có liên quan nhất tới ngành nghề này giúp mình nha)\n",
    "----\n",
    "text: {job_description}\n",
    "----\n",
    "Trả về thông tin theo định dạng JSON như sau:\n",
    "{{\n",
    "    \"job_description\": \"\",\n",
    "    \"job_responsibility\": \"\",\n",
    "    \"job_requirements\": \"\",\n",
    "    \"require_tools\": [],\n",
    "    \"require_skills\": [],\n",
    "    \"require_certificate\": []\n",
    "    \"job_experience\": \"\",\n",
    "    \"education_level\": \"\",\n",
    "    \"education_major\": \"\"\n",
    "}}\n",
    "Chỉ trả về thông tin theo dạng trên theo tiếng Anh, không thêm phần giới thiệu hay kết luận nào khác. Ngoài ra đừng trả về dưới dạng markdown.\n",
    "Ngoài ra, tất đối với require_tools, require_skills, require_certificate, education_level, education_major thì tất cả không viết hoa.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6445b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=googleai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requirement(job_description):\n",
    "    chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "    \n",
    "    prompt = DEFINE_PROMPT.format(job_description=job_description)\n",
    "    \n",
    "    response = chat.send_message(\n",
    "        message=prompt,\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_parse_json(raw_response):\n",
    "    cleaned = raw_response.strip()\n",
    "\n",
    "    # Remove markdown (```json ... ```)\n",
    "    cleaned = re.sub(r\"^```json\\s*|\\s*```$\", \"\", cleaned, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # Replace None (Python) to null (JSON)\n",
    "    cleaned = cleaned.replace(\"None\", \"null\")\n",
    "\n",
    "    # if \"null\" return as string then return null as value\n",
    "    cleaned = re.sub(r'\"\\s*null\\s*\"', 'null', cleaned)\n",
    "\n",
    "    # Sometime it return both version in English and Vietnamese, so we need to remove the Vietnamese version\n",
    "    if cleaned.count(\"{\") > 1:\n",
    "        cleaned = cleaned.split(\"}\", 1)[0] + \"}\"\n",
    "\n",
    "    # Parse JSON\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSONDecodeError:\", e)\n",
    "        print(\"Error string:\", repr(cleaned))\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_category = []\n",
    "domain = []\n",
    "job_descriptions = []\n",
    "job_responsibilities = []\n",
    "job_requirements = []\n",
    "tools = []\n",
    "skills = []\n",
    "certs = []\n",
    "job_experience = []\n",
    "education_level = []\n",
    "education_major = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    try:\n",
    "        result = extract_requirement(row[\"Job Context\"])\n",
    "        parsed = clean_and_parse_json(result)\n",
    "\n",
    "        work_category.append(parsed.get(\"work_category\", \"\"))\n",
    "        domain.append(parsed.get(\"domain\", \"\"))\n",
    "        job_descriptions.append(parsed.get(\"job_description\", \"\"))\n",
    "        job_responsibilities.append(parsed.get(\"job_responsibility\", \"\"))\n",
    "        job_requirements.append(parsed.get(\"job_requirements\", \"\"))\n",
    "        tools.append(\", \".join(x for x in parsed.get(\"require_tools\") or [] if x))\n",
    "        skills.append(\", \".join(x for x in parsed.get(\"require_skills\") or [] if x))\n",
    "        certs.append(\", \".join(x for x in parsed.get(\"require_certificate\") or [] if x))\n",
    "        job_experience.append(parsed.get(\"job_experience\", \"\"))\n",
    "        education_level.append(parsed.get(\"eduction_level\", \"\"))\n",
    "        education_major.append(parsed.get(\"eduction_major\", \"\"))\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {idx}: {e}\")\n",
    "\n",
    "    # Due to the rpm limitation of Google AI, we need to sleep for 20 seconds after each request\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Work Category\"] = work_category\n",
    "df[\"Domain\"] = domain\n",
    "df[\"Job Description New\"] = job_descriptions\n",
    "df[\"Job Responsibility\"] = job_responsibilities\n",
    "df[\"Job Requirements\"] = job_requirements\n",
    "df[\"Job Experience\"] = job_experience\n",
    "df[\"Education Level\"] = education_level\n",
    "df[\"Education Major\"] = education_major\n",
    "df[\"Require Tools\"] = tools\n",
    "df[\"Require Skills\"] = skills\n",
    "df[\"Require Certificate\"] = certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV file for backup\n",
    "df.to_csv(\"Broadcom_job_data_v2.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9c4e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set width of column A (header 'Company') to 30\n",
      "Set width of column B (header 'Job Title') to 50\n",
      "Set width of column C (header 'Job Location') to 30\n",
      "Set width of column D (header 'Date Posted') to 30\n",
      "Set width of column E (header 'Employment Type') to 30\n",
      "Set width of column F (header 'Job ID') to 30\n",
      "Set width of column G (header 'Job Description') to 50\n",
      "Set width of column H (header 'Job Context') to 50\n",
      "Set width of column I (header 'Job Description New') to 50\n",
      "Set width of column J (header 'Job Responsibility') to 50\n",
      "Set width of column K (header 'Job Requirements') to 50\n",
      "Set width of column L (header 'Job Experience') to 15\n",
      "Set width of column M (header 'Education Level') to 15\n",
      "Set width of column N (header 'Education Major') to 15\n",
      "Set width of column O (header 'Require Tools') to 25\n",
      "Set width of column P (header 'Require Skills') to 25\n",
      "Set width of column Q (header 'Require Certificate') to 25\n",
      "Set width of column R (header 'Work Category') to 20\n",
      "Set width of column S (header 'Domain') to 20\n"
     ]
    }
   ],
   "source": [
    "wb = load_workbook(\"Broadcom_job_data_v2.xlsx\")\n",
    "ws = wb.active\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "company = \"Broadcom\"\n",
    "\n",
    "# Định nghĩa độ rộng cột\n",
    "column_settings = {\n",
    "    (\"Job Title\", \"Job Description\", \"Job Description New\", \"Job Responsibility\", \"Job Requirements\", \"Job Context\"): 50,\n",
    "    (\"Company\", \"Job Location\", \"Date Posted\", \"Employment Type\", \"Job ID\"): 30,\n",
    "    (\"Work Category\", \"Domain\"): 20,\n",
    "    (\"Require Tools\", \"Require Skills\", \"Require Certificate\"): 25,\n",
    "    (\"Job Experience\", \"Education Level\", \"Education Major\"): 15,\n",
    "    (\"Link\",): 50,\n",
    "}\n",
    "\n",
    "# Thiết lập độ rộng cột và bật wrap_text\n",
    "for cell in ws[1]:  # Lặp qua hàng đầu tiên (header)\n",
    "    if cell.value:\n",
    "        header = cell.value.strip()\n",
    "        for headers, width in column_settings.items():\n",
    "            if header in headers:\n",
    "                col_letter = get_column_letter(cell.column)\n",
    "                ws.column_dimensions[col_letter].width = width\n",
    "                print(f\"Set width of column {col_letter} (header '{header}') to {width}\")\n",
    "\n",
    "                # Bật wrap_text cho tất cả các ô trong cột\n",
    "                for row in ws.iter_rows(min_col=cell.column, max_col=cell.column, min_row=2, max_row=ws.max_row):\n",
    "                    for c in row:\n",
    "                        c.alignment = Alignment(wrap_text=True)\n",
    "\n",
    "# Căn chỉnh toàn bộ sheet\n",
    "for row in ws.iter_rows():\n",
    "    for cell in row:\n",
    "        if cell.alignment:\n",
    "            cell.alignment = Alignment(\n",
    "                horizontal=cell.alignment.horizontal or \"left\",\n",
    "                vertical=\"top\",\n",
    "                text_rotation=cell.alignment.text_rotation,\n",
    "                wrap_text=cell.alignment.wrap_text,\n",
    "                shrink_to_fit=cell.alignment.shrink_to_fit,\n",
    "                indent=cell.alignment.indent\n",
    "            )\n",
    "\n",
    "# Hàm tự động điều chỉnh chiều cao hàng dựa trên wrap_text\n",
    "def auto_adjust_row_heights(worksheet, base_height=15, words_per_line=7):\n",
    "    for row in worksheet.iter_rows(min_row=1, max_row=worksheet.max_row):\n",
    "        max_lines = 1\n",
    "        for cell in row:\n",
    "            if cell.alignment and cell.alignment.wrap_text and cell.value:\n",
    "                lines = str(cell.value).split('\\n')\n",
    "                estimated_lines = sum((len(line.split()) + words_per_line - 1) // words_per_line for line in lines)\n",
    "                max_lines = max(max_lines, estimated_lines)\n",
    "        worksheet.row_dimensions[row[0].row].height = base_height * max_lines\n",
    "\n",
    "# Điều chỉnh chiều cao hàng\n",
    "auto_adjust_row_heights(ws)\n",
    "\n",
    "# Lưu file Excel mới\n",
    "output_file = f\"./{company}_job_posts_allcountries_raw_{today}.xlsx\"\n",
    "wb.save(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
